{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shakespeare-text-generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramapriyakp/Portfolio/blob/master/NLP/Shakespeare_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7sYqt_YoqKw",
        "colab_type": "text"
      },
      "source": [
        "# Text Generation using LSTMs\n",
        "Text Generation is a type of Language Modelling problem. Language Modelling is the core problem for a number of of natural language processing tasks such as speech to text, conversational system, and text summarization.\n",
        "\n",
        "A trained language model learns the likelihood of occurrence of a word based on the previous sequence of words used in the text. Language models can be operated at character level, n-gram level, sentence level or even paragraph level. In this notebook, we will create a language model for generating natural language text by implement and training state-of-the-art Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        " \n",
        "# Figure out how to import regularizers\n",
        "import tensorflow.keras.regularizers as regularizers\n",
        "###\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r791G9TYIs7F",
        "colab_type": "code",
        "outputId": "3647c882-ec6c-46dd-d172-9bf18a62f91e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWt33YIxg_rF",
        "colab_type": "text"
      },
      "source": [
        "##Class Tokenizer\n",
        "Text tokenization utility class.\n",
        "\n",
        "This class allows to vectorize a text corpus, by turning each text into either a sequence of integers\n",
        "(each integer being the index of a token in a dictionary) or into a vector where the coefficient\n",
        "for each token could be binary, based on word count, based on tf-idf...\n",
        "\n",
        "**fit_on_texts(texts)**\n",
        "\n",
        "Updates internal vocabulary based on a list of texts.\n",
        "In the case where texts contains lists, we assume each entry of the lists to be a token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRnDnCW-Z7qv",
        "outputId": "9e3ed636-1924-4842-d8bf-8f9ea1f487ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-30 16:14:24--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.160.16, 2404:6800:4003:80d::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.160.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-08-30 16:14:25 (109 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_kpr-VXegVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r72cyvmVyb-Q",
        "colab_type": "text"
      },
      "source": [
        "## 4. LSTMs for Text Generation\n",
        " Recurrent neural networks have shown a good performance in sequence to sequence learning and text data applications. Lets look at them in brief.\n",
        "\n",
        "\n",
        "\n",
        "![](http://www.shivambansal.com/blog/text-lstm/2.png)\n",
        "\n",
        "Unlike Feed-forward neural networks in which activation outputs are propagated only in one direction, the activation outputs from neurons propagate in both directions (from inputs to outputs and from outputs to inputs) in Recurrent Neural Networks. This creates loops in the neural network architecture which acts as a ‘memory state’ of the neurons. This state allows the neurons an ability to remember what have been learned so far.\n",
        "\n",
        "The memory state in RNNs gives an advantage over traditional neural networks but a problem called Vanishing Gradient is associated with them. In this problem, while learning with a large number of layers, it becomes really hard for the network to learn and tune the parameters of the earlier layers. To address this problem, A new type of RNNs called LSTMs (Long Short Term Memory) Models have been developed.\n",
        "\n",
        "LSTMs have an additional state called ‘cell state’ through which the network makes adjustments in the information flow. The advantage of this state is that the model can remember or forget the leanings more selectively. To learn more about LSTMs, here is a great post. Lets architecture a LSTM model in our code. I have added total three layers in the model.\n",
        "\n",
        "1. Input Layer : Takes the sequence of words as input.Keras offers an Embedding layer that can be used for neural networks on text data.\n",
        "2. LSTM Layer : Computes the output using LSTM units. I have added 100 units in the layer, but this number can be fine tuned later.\n",
        "3. Dropout Layer : A regularisation layer which randomly turns-off the activations of some neurons in the LSTM layer. It helps in preventing over fitting. (Optional Layer)\n",
        "4. Output Layer : Computes the probability of the best possible next word as output\n",
        "\n",
        "We will run this model for total 100 epoochs but it can be experimented further.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab_type": "code",
        "outputId": "9d51cd53-8944-42bd-bea8-463d1a14d9de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0830 16:14:37.407517 140239690790784 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0830 16:14:37.434170 140239690790784 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0830 16:14:37.440778 140239690790784 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0830 16:14:37.441781 140239690790784 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0830 16:14:37.443146 140239690790784 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10, 100)           321100    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 200)           160800    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10, 200)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 50)                50200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1605)              81855     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3211)              5156866   \n",
            "=================================================================\n",
            "Total params: 5,770,821\n",
            "Trainable params: 5,770,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVIERhbhgFIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pick an optimizer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvKsqdpBiQZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import History, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "history_with_reg = History()\n",
        "es = EarlyStopping(patience=10, monitor='acc')\n",
        "mc = ModelCheckpoint(\"seq_model_with_reg.h5\", monitor='acc', \n",
        "                     save_best_only=True, load_weights_on_restart=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIg2f1HBxqof",
        "colab_type": "code",
        "outputId": "cbd721ff-6035-4e9f-a533-d91485625317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(predictors, label, epochs=100, verbose=1, callbacks=[history_with_reg, mc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0830 16:15:16.600243 140239690790784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15462/15462 [==============================] - 26s 2ms/sample - loss: 6.8844 - acc: 0.0213\n",
            "Epoch 2/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.4994 - acc: 0.0219\n",
            "Epoch 3/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.3952 - acc: 0.0243\n",
            "Epoch 4/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.2692 - acc: 0.0279\n",
            "Epoch 5/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.1805 - acc: 0.0328\n",
            "Epoch 6/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.1051 - acc: 0.0369\n",
            "Epoch 7/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.0250 - acc: 0.0391\n",
            "Epoch 8/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.9548 - acc: 0.0418\n",
            "Epoch 9/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.8745 - acc: 0.0476\n",
            "Epoch 10/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.7828 - acc: 0.0523\n",
            "Epoch 11/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.6846 - acc: 0.0586\n",
            "Epoch 12/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.5835 - acc: 0.0648\n",
            "Epoch 13/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.4799 - acc: 0.0719\n",
            "Epoch 14/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.3776 - acc: 0.0790\n",
            "Epoch 15/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.2825 - acc: 0.0865\n",
            "Epoch 16/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.1810 - acc: 0.0935\n",
            "Epoch 17/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.0909 - acc: 0.1008\n",
            "Epoch 18/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.9980 - acc: 0.1079\n",
            "Epoch 19/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.9086 - acc: 0.1176\n",
            "Epoch 20/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.8209 - acc: 0.1228\n",
            "Epoch 21/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.7309 - acc: 0.1315\n",
            "Epoch 22/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.6466 - acc: 0.1366\n",
            "Epoch 23/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.5627 - acc: 0.1450\n",
            "Epoch 24/100\n",
            "15462/15462 [==============================] - 23s 2ms/sample - loss: 4.4765 - acc: 0.1549\n",
            "Epoch 25/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.3971 - acc: 0.1612\n",
            "Epoch 26/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.3179 - acc: 0.1706\n",
            "Epoch 27/100\n",
            "15462/15462 [==============================] - 23s 2ms/sample - loss: 4.2339 - acc: 0.1816\n",
            "Epoch 28/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.1549 - acc: 0.1868\n",
            "Epoch 29/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.0774 - acc: 0.1998\n",
            "Epoch 30/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.0065 - acc: 0.2051\n",
            "Epoch 31/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.9235 - acc: 0.2192\n",
            "Epoch 32/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.8505 - acc: 0.2283\n",
            "Epoch 33/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.7751 - acc: 0.2449\n",
            "Epoch 34/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.7001 - acc: 0.2588\n",
            "Epoch 35/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.6411 - acc: 0.2691\n",
            "Epoch 36/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.5625 - acc: 0.2815\n",
            "Epoch 37/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.5057 - acc: 0.2938\n",
            "Epoch 38/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.4397 - acc: 0.3153\n",
            "Epoch 39/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.3834 - acc: 0.3212\n",
            "Epoch 40/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.3141 - acc: 0.3370\n",
            "Epoch 41/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.2552 - acc: 0.3533\n",
            "Epoch 42/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.2043 - acc: 0.3604\n",
            "Epoch 43/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.1421 - acc: 0.3757\n",
            "Epoch 44/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.0933 - acc: 0.3854\n",
            "Epoch 45/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.0367 - acc: 0.3972\n",
            "Epoch 46/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.9830 - acc: 0.4124\n",
            "Epoch 47/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.9401 - acc: 0.4211\n",
            "Epoch 48/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.8945 - acc: 0.4284\n",
            "Epoch 49/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.8437 - acc: 0.4400\n",
            "Epoch 50/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.8005 - acc: 0.4494\n",
            "Epoch 51/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.7569 - acc: 0.4599\n",
            "Epoch 52/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.7137 - acc: 0.4693\n",
            "Epoch 53/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.6748 - acc: 0.4779\n",
            "Epoch 54/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.6180 - acc: 0.4880\n",
            "Epoch 55/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.5809 - acc: 0.4986\n",
            "Epoch 56/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.5517 - acc: 0.5070\n",
            "Epoch 57/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.5135 - acc: 0.5133\n",
            "Epoch 58/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.4826 - acc: 0.5160\n",
            "Epoch 59/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.4309 - acc: 0.5298\n",
            "Epoch 60/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.3974 - acc: 0.5387\n",
            "Epoch 61/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.3551 - acc: 0.5444\n",
            "Epoch 62/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.3290 - acc: 0.5511\n",
            "Epoch 63/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.3006 - acc: 0.5573\n",
            "Epoch 64/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.2611 - acc: 0.5702\n",
            "Epoch 65/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.2298 - acc: 0.5755\n",
            "Epoch 66/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.2043 - acc: 0.5776\n",
            "Epoch 67/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.1726 - acc: 0.5878\n",
            "Epoch 68/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.1497 - acc: 0.5897\n",
            "Epoch 69/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.1161 - acc: 0.6004\n",
            "Epoch 70/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.0951 - acc: 0.6050\n",
            "Epoch 71/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.0670 - acc: 0.6056\n",
            "Epoch 72/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.0390 - acc: 0.6139\n",
            "Epoch 73/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.0110 - acc: 0.6227\n",
            "Epoch 74/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.9763 - acc: 0.6283\n",
            "Epoch 75/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.9583 - acc: 0.6320\n",
            "Epoch 76/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.9283 - acc: 0.6407\n",
            "Epoch 77/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.9137 - acc: 0.6435\n",
            "Epoch 78/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.9036 - acc: 0.6438\n",
            "Epoch 79/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.8741 - acc: 0.6483\n",
            "Epoch 80/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.8502 - acc: 0.6547\n",
            "Epoch 81/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.8359 - acc: 0.6544\n",
            "Epoch 82/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.8048 - acc: 0.6653\n",
            "Epoch 83/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.7970 - acc: 0.6640\n",
            "Epoch 84/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.7801 - acc: 0.6686\n",
            "Epoch 85/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.7432 - acc: 0.6775\n",
            "Epoch 86/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.7162 - acc: 0.6811\n",
            "Epoch 87/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.7162 - acc: 0.6840\n",
            "Epoch 88/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.6956 - acc: 0.6810\n",
            "Epoch 89/100\n",
            "15462/15462 [==============================] - 26s 2ms/sample - loss: 1.6737 - acc: 0.6938\n",
            "Epoch 90/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.6556 - acc: 0.6951\n",
            "Epoch 91/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.6492 - acc: 0.6919\n",
            "Epoch 92/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.6252 - acc: 0.7009\n",
            "Epoch 93/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.5994 - acc: 0.7055\n",
            "Epoch 94/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.5930 - acc: 0.7072\n",
            "Epoch 95/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.5779 - acc: 0.7095\n",
            "Epoch 96/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.5648 - acc: 0.7132\n",
            "Epoch 97/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.5448 - acc: 0.7189\n",
            "Epoch 98/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.5343 - acc: 0.7171\n",
            "Epoch 99/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.5272 - acc: 0.7196\n",
            "Epoch 100/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.4927 - acc: 0.7267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8bbc3626d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXTEO3GJ282",
        "colab_type": "code",
        "outputId": "b6194eec-a3b7-40af-fcd5-e34c03825bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "history = history_with_reg\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEkNK7iIiMfT/g111uyeJpnIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMw6DVLapgZ2",
        "colab_type": "text"
      },
      "source": [
        "## 5. Generating the text \n",
        "\n",
        "Great, our model architecture is now ready and we can train it using our data. Next lets write the function to predict the next word based on the input words (or seed text). We will first tokenize the seed text, pad the sequences and pass into the trained model to get predicted word. The multiple predicted words can be appended together to get predicted sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab_type": "code",
        "outputId": "b7a707e5-f59d-4650-9c6e-88e242d78fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope or this viewest survey gems wit green weep decays this ride lie in me a show good show many forth brow 'will ' ' still have behold and give stay away be much strong part bright bright show thee told thee worth told it most 'will' is loving shouldst confound dispense else mistaking seen seen strive not back of done no odours made to stay things skill give store now give harvest cross'd kill'd kill'd cross'd proceed remain need interest days can see down thence give groan new cheeks wretch suspect and mine eye be of heart so show it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rJPKKlls2bY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlPlIshCuFeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}